# HealthLens AI ğŸ©º

## Personal Health Coach powered by LLMs & Context Compression

HealthLens AI is an AI-powered personal health analysis system that collects user health data and generates meaningful insights, risk analysis, and personalized recommendations. The project uses local Large Language Models (Ollama) to deliver efficient, cost-effective AI reasoning.

## ğŸš€ Features

Collects health inputs: age, gender, BMI, sleep, steps, medical history, and symptoms

Compresses user health context using ScaleDown API

Generates AI-driven health summaries and insights using Ollama (local LLM)

Detects potential health risks and explains them in natural language

Provides personalized lifestyle and wellness recommendations

Visualizes health metrics using charts

Fully local inference (no paid OpenAI API required)

## ğŸ§  Architecture Overview
User Input
   â†“
ScaleDown Context Compression
   â†“
Local LLM (Ollama: Phi-3 / Llama-3)
   â†“
Risk Analysis + Recommendations
   â†“
Streamlit UI (Health Report)

## ğŸ› ï¸ Tech Stack

Python

Streamlit â€“ frontend UI

Ollama â€“ local LLM inference

ScaleDown API â€“ context compression

Matplotlib â€“ data visualization

Requests â€“ API communication

## ğŸ“ Project Structure
HealthMonitoringAgent/
â”‚
â”œâ”€â”€ app.py              # Streamlit application
â”œâ”€â”€ agents.py           # AI agents (compression, risk, recommendation)
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ background.jpg
â”‚   â”œâ”€â”€ header.png
â”‚   â””â”€â”€ health2.png
â””â”€â”€ README.md

## âš™ï¸ Installation & Setup
1ï¸âƒ£ Install dependencies
pip install streamlit matplotlib requests ollama

2ï¸âƒ£ Install & run Ollama

Download Ollama from: https://ollama.com

Start a local model:

ollama run phi3
# or
ollama run llama3


âš ï¸ Keep Ollama running in the background.

3ï¸âƒ£ Run the application
streamlit run app.py

## ğŸ“Š Example Output

Compressed health profile

Detected health risks

AI symptom analysis

Personalized health recommendations

Visual BMI, sleep, and activity metrics

## ğŸ¯ Why This Project Stands Out

Uses LLMs responsibly with context compression

Works offline using local AI models

Reduces token cost and latency

Modular AI agent design

Competition-ready and scalable

## âš ï¸ Disclaimer

This project is intended for educational and research purposes only.
It does not provide medical diagnoses or replace professional medical advice.

## ğŸ‘©â€ğŸ’» Author

Vanshika Asthana
AI / ML Enthusiast | Student Developer

## â­ Future Enhancements

PDF report export

Multi-language support

Wearable device integration

Long-term health tracking

Model switching UI (Phi-3 / Llama-3)
